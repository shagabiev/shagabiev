{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4: 0.5102\n",
      "Document 1: -0.1200\n",
      "Document 3: -0.1200\n",
      "Document 5: -0.1200\n",
      "Document 2: -0.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romanmolochkov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/romanmolochkov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "documents = [\n",
    "    'Information Retrieval is a field of computer science',\n",
    "    'Natural Language Processing is a subfield of computer science',\n",
    "    'Machine Learning overlaps with Information Retrieval and Natural Language Processing',\n",
    "    'Probabilistic models are used for prediction in many fields including IR and NLP',\n",
    "    'Evaluation of Information Retrieval systems is crucial'\n",
    "]\n",
    "\n",
    "query = 'Probabilistic Information Retrieval'\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "tokenized_documents = [preprocess(doc) for doc in documents]\n",
    "tokenized_query = preprocess(query)\n",
    "\n",
    "tf = defaultdict(int)\n",
    "for term in tokenized_query:\n",
    "    for i, doc in enumerate(tokenized_documents):\n",
    "        tf[(term, i+1)] = doc.count(term)\n",
    "\n",
    "df = defaultdict(int)\n",
    "for term in tokenized_query:\n",
    "    for doc in tokenized_documents:\n",
    "        if term in doc:\n",
    "            df[term] += 1\n",
    "\n",
    "idf = {term: math.log(len(tokenized_documents) / df[term]) for term in tokenized_query}\n",
    "\n",
    "backup = 0.5\n",
    "scores = []\n",
    "for i, doc in enumerate(tokenized_documents, start=1):\n",
    "    score = 1\n",
    "    for term in tokenized_query:\n",
    "        if term not in idf:\n",
    "            continue\n",
    "        R = tf[(term, i)]\n",
    "        r = df[term]\n",
    "\n",
    "        numerator = (R - r + backup)\n",
    "        denominator = (r - R + backup)\n",
    "        score *= numerator / denominator\n",
    "\n",
    "    scores.append((i, score))\n",
    "\n",
    "sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "for doc_id, score in sorted_scores:\n",
    "    print(f'Document {doc_id}: {score:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
